{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn from Scratch\n",
    "\n",
    "My Question,,, CPU VS Accelerator\n",
    "## 1️. CPU vs Accelerator\n",
    "\n",
    "> **CPU**: 적은 수의 코어, 복잡한 일 잘함\n",
    "> **Accelerator(GPU 등)**: 단순 계산을 엄청 많이 동시에 하는 공장 (코어 수 수천 개)\n",
    "\n",
    "딥러닝/텐서 연산은 **“같은 계산을 숫자 엄청 많이에 대해 반복”** → accelerator가 압도적으로 빠름.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. CPU\n",
    "\n",
    "### CPU 특징\n",
    "\n",
    "* 코어 수: 보통 **4~16개** // 구매할때도 보통 그 옵션 ..\n",
    "* 각 코어가 고능\n",
    "* 분기(if), 로직, OS, 프로그램 제어에 최적화\n",
    "\n",
    "### 잘하는 일\n",
    "\n",
    "* 프로그램 실행\n",
    "* 조건문, 반복문\n",
    "* 파일 I/O\n",
    "* 전체 흐름 제어\n",
    "\n",
    "### 하지만…\n",
    "\n",
    "```text\n",
    "행렬 10000 × 10000 곱하기\n",
    "```\n",
    "\n",
    "같은 **순수 수치 계산**은 느림\n",
    "\n",
    "---\n",
    "\n",
    "## 3️. Accelerator (GPU 등)\n",
    "\n",
    "### 공통 특징\n",
    "\n",
    "* 코어 수: **수천~수만 개**\n",
    "* 각 코어는 **아주 단순**\n",
    "* 같은 연산을 동시에 수많은 데이터에 적용\n",
    "\n",
    ">  **행렬, 텐서 계산 특화**\n",
    "\n",
    "---\n",
    "\n",
    "## 4️. CUDA (⭐)\n",
    "\n",
    "### CUDA = NVIDIA GPU 전용 가속 플랫폼\n",
    "\n",
    "* NVIDIA GPU에서 계산을 하기 위한\n",
    "\n",
    "  * 프로그래밍 모델\n",
    "  * 드라이버\n",
    "  * 라이브러리 묶음\n",
    "\n",
    "### 그래서\n",
    "\n",
    "```python\n",
    "device = \"cuda\"\n",
    "x = x.to(device)\n",
    "```\n",
    "\n",
    "> “이 텐서를 **NVIDIA GPU 메모리**로 옮겨서\n",
    "> GPU 코어들한테 계산시키겠다”\n",
    "\n",
    "라는 뜻\n",
    "\n",
    "⚠️ **CUDA ≠ GPU**\n",
    "\n",
    "* GPU: 하드웨어\n",
    "* CUDA: NVIDIA GPU를 쓰기 위한 **소프트웨어 생태계**\n",
    "\n",
    "---\n",
    "\n",
    "## 5️. MPS / XPU / MTIA ... ?\n",
    "\n",
    "### 🔹 MPS (Metal Performance Shaders)\n",
    "\n",
    "* **Apple Silicon (M1/M2/M3)** GPU용\n",
    "* macOS에서 PyTorch 가속\n",
    "\n",
    "```python\n",
    "device = \"mps\"\n",
    "```\n",
    "\n",
    "### 🔹 XPU\n",
    "\n",
    "* Intel GPU / 가속기\n",
    "* PyTorch에서 Intel 생태계 대응\n",
    "\n",
    "### 🔹 MTIA\n",
    "\n",
    "* Meta(Facebook) 내부 AI 가속기\n",
    "* 일반 유저는 거의 안 씀\n",
    "\n",
    "---\n",
    "\n",
    "## 6️. Why do we use `.to(device)` ?\n",
    "\n",
    "### We use CPU as default\n",
    "\n",
    "```python\n",
    "x = torch.tensor([1, 2, 3])\n",
    "```\n",
    "\n",
    "👉 **무조건 CPU 메모리**\n",
    "\n",
    "### EVEN IF WE HAVE GPU\n",
    "\n",
    "> **WHY?**\n",
    "> * GPU 메모리는 비쌈\n",
    "> * 옮기는 비용도 있음\n",
    "> * 명시적으로 관리해야 안전함\n",
    "\n",
    "\n",
    "```python\n",
    "x = x.to(\"cuda\")\n",
    "```\n",
    "\n",
    "### ⚠️ 흔한 에러\n",
    "\n",
    "```text\n",
    "RuntimeError: Expected all tensors to be on the same device\n",
    "```\n",
    "\n",
    "= CPU 텐서랑 GPU 텐서를 섞어 썼다는 뜻\n",
    "\n",
    "---\n",
    "\n",
    "## 7️. 왜 딥러닝에 GPU가 필수일까..\n",
    "\n",
    "### 예시: 행렬곱\n",
    "\n",
    "```text\n",
    "(10000 × 10000) × (10000 × 10000)\n",
    "```\n",
    "\n",
    "* CPU: 몇 초~몇 분\n",
    "* GPU: **몇 ms ~ 수십 ms**\n",
    "\n",
    "딥러닝은 이걸 **수천 번 반복**함.\n",
    "\n",
    "---\n",
    "\n",
    "## 정리\n",
    "\n",
    "| 구분             | CPU     | Accelerator (GPU 등) |\n",
    "| -------------- | ------- | ------------------- |\n",
    "| 코어 수           | 적음      | 매우 많음               |\n",
    "| 연산             | 복잡한 로직  | 단순 수치 연산            |\n",
    "| 딥러닝            | 느림      | 필수                  |\n",
    "| PyTorch device | `\"cpu\"` | `\"cuda\"`, `\"mps\"`   |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
