{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">Python Programming for Machine Learning</h1>\n",
    "<h2 align=\"center\">Case Studies</h2>\n",
    "\n",
    "<center><img src='images/python-logo-only.svg' width=250> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib\n",
    "\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Matplotlib: {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder:\n",
    "- Lecturer: Have you started the recording?\n",
    "- Audience: Have you received a notification that the recording has started?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture:\n",
    "\n",
    "- Walks through several \"independent\" concepts\n",
    "- Some parts contain examples from real codebases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional background: [introductory OOP lecture from MIT](https://www.youtube.com/watch?v=-DP1i2ZU9gk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> â€œDevelopers should always understand one layer of abstraction below their everyday work.â€\n",
    ">\n",
    "> Glenn Vanderburg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterables & Iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ general example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: implementing a dataset and dataloader \"from scratch\":\n",
    "```python\n",
    "dataset = Dataset([1, 2, 3, 4, 5, 6])\n",
    "dataloader = Dataloader(dataset)\n",
    "\n",
    "for epoch in range(2):\n",
    "    for item in dataloader:\n",
    "        print(item)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data container / iterable\n",
    "class Dataset:\n",
    "    def __init__(self, items):  #Â initialize instance: `dataset = Dataset(...)``\n",
    "        self.items = items\n",
    "\n",
    "    def __getitem__(self, idx):  # retrieve item: `dataset[1]``\n",
    "        return self.items[idx]\n",
    "\n",
    "    def __len__(self):  # get length: `len(dataset)`\n",
    "        return len(self.items)\n",
    "\n",
    "    # `__iter__` defines how to iterate\n",
    "    # if undefined, Python falls back to simple sequential iteration\n",
    "    # def __iter__(self):\n",
    "    #     for cnt, item in enumerate(self.items):\n",
    "    #         if cnt % 2:\n",
    "    #             yield item\n",
    "\n",
    "\n",
    "dataset = Dataset([1, 2, 3, 4, 5, 6])\n",
    "dataset[1], len(dataset), \"__iter__\" in dir(dataset), [v for v in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design choice: decouple dataset from dataloader (e.g., to use one dataloader for several datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterable\n",
    "class Dataloader:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self.dataset)):\n",
    "            yield self.dataset[i]  # `yield` creates iterator\n",
    "\n",
    "        # More verbose alternative\n",
    "        # return DataloaderIterator(self.dataset)\n",
    "\n",
    "\n",
    "# class DataloaderIterator:\n",
    "#     def __init__(self, dataset):\n",
    "#         self.dataset = dataset\n",
    "#         self.index = 0\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         return self\n",
    "\n",
    "#     # Defines \"position\" in dataset & gives next item\n",
    "#     def __next__(self):\n",
    "#         if self.index < len(self.dataset):\n",
    "#             item = self.dataset[self.index]\n",
    "#             self.index += 1\n",
    "#             return item\n",
    "#         raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = Dataloader(dataset)\n",
    "\n",
    "for epoch in range(2):\n",
    "    print(\"new epoch\")\n",
    "    for item in dataloader:  # Each epoch gets fresh iterator\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is syntactic sugar for the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = Dataloader(dataset)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    # done by for loop behind the scenes\n",
    "    # each call of `iter` returns own state (=iterator)\n",
    "    iterator = iter(dataloader)\n",
    "\n",
    "    while True:  # loop until the iterator is exhausted\n",
    "        try:\n",
    "            item = next(iterator)  # done by for loop behind the scenes\n",
    "            print(item)\n",
    "        except StopIteration:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ [openai/improved-diffusion](https://github.com/openai/improved-diffusion)\n",
    "\n",
    "**Repo purpose:** diffusion models for images (see the diffusion model lecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application example**\n",
    "\n",
    "Source: `improved_diffusion/image_dataset.py`\n",
    "- Class `ImageDataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageDataset(Dataset)\n",
    "    def __init__(self, resolution, image_paths, *args, classes=None, shard=0, num_shards=1, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.resolution = resolution\n",
    "        self.local_images = image_paths[shard:][::num_shards]\n",
    "        self.local_classes = None if classes is None else classes[shard:][::num_shards]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.local_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.local_images[idx]\n",
    "        with bf.BlobFile(path, \"rb\") as f:  # This is a context manager. More on this later.\n",
    "            pil_image = Image.open(f)\n",
    "            pil_image.load()\n",
    "\n",
    "        # We may want preprocess data, e.g., standardize image aspect ratio\n",
    "        [...]\n",
    "\n",
    "        return np.transpose(arr, [2, 0, 1]), out_dict\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ [facebookresearch/chameleon](https://github.com/facebookresearch/chameleon)\n",
    "\n",
    "**Repo purpose:** Mixed-modal models\n",
    "- Similar to autoregressive language models, but support more modalities like text **and** images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application example:**\n",
    "\n",
    "Source: `chameleon/inference/generation.py`\n",
    "\n",
    "Class `ChameleonGenerator`: implements autoregressive (token by token) generation of the model via `__next__`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "- Iteration logic can be complex: not just dataloading: e.g. next-token prediction, streaming\n",
    "- Several implementation tools: `__iter__`/`__next__`, generator functions, library helpers (e.g. dataloaders)\n",
    "  - Generators: `__iter__` returns self, `__next__` runs to next `yield` (`return` â†’ `StopIteration`)\n",
    "\n",
    "> **ðŸ’¡ No single â€œbestâ€ tool: your job is to choose good abstractions for the context. This requires experience & expertise!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overwriting / operator overloading & decorators/context managers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ General example\n",
    "\n",
    "**Overwriting:** replace (or extend via `super`) function via inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        print(f\"Name: {name}\")\n",
    "\n",
    "    def move(self):\n",
    "        print(f\"{self.name} is moving\")\n",
    "\n",
    "\n",
    "class Bird(Animal):\n",
    "    def __init__(self, wings: bool, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)  # super() points to parent class (â†’ we don't lose parent class logic)\n",
    "        self.wings = wings\n",
    "\n",
    "    def fly(self):\n",
    "        print(\"Flying\")\n",
    "\n",
    "\n",
    "duck = Bird(wings=True, name=\"Daffy\")\n",
    "duck.fly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ general example\n",
    "\n",
    "- Operator overloading (Python): same symbol (`+`) â†’ type-dependent behavior\n",
    "  - Implemented via dunder methods: `__add__`, `__radd__`, ...\n",
    "- Function overloading (e.g., Java): same function name, many signatures: **not** relevant here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dough:\n",
    "\n",
    "    def __init__(self, weight=0.5, volume=0.5):\n",
    "        self.weight = weight\n",
    "        self.volume = volume\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Dough(weight={self.weight}, volume={self.volume})\"\n",
    "\n",
    "    # operator overloading of `+`\n",
    "    def __add__(self, other):  # instance_1 + instance_2\n",
    "        # `type(self)` returns the class (`Dough`)\n",
    "        return type(self)(self.weight + other.weight, self.volume + other.volume)\n",
    "        # the below has identical behavior in *this* example, but may break when subclassing `Dough` without overwriting `__add__`\n",
    "        # return Dough(self.weight + other.weight, self.volume + other.volume)\n",
    "\n",
    "    # In-place addition (more memory efficient than `__add__`!)\n",
    "    def __iadd__(self, other):  # instance_1 += instance_2\n",
    "        self.weight += other.weight\n",
    "        self.volume += other.volume\n",
    "        return self\n",
    "\n",
    "    def __mul__(self, other):  # instance_1 * instance_2\n",
    "        return type(self)(self.weight * other.weight, self.volume * other.volume)\n",
    "\n",
    "    def __rmul__(self, other):  # scalar * instance\n",
    "        return type(self)(self.weight * other, self.volume * other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dough = Dough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dough  # calls __repr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dough += Dough(5, 5)  # calls __iadd__\n",
    "dough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 * Dough(5, 5)  # calls __rmul__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dough(1) + Dough()  # calls __add__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dough() * Dough()  # calls __mul__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decorators & Context Managers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decorators were introduced in a previous lecture.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ General example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n",
    "- Build abstraction that:\n",
    "  - performs computation before/after a function or code block\n",
    "  - optionally also adjusts the function behavior/output\n",
    "- Why abstraction (not: write this out \"manually\")?\n",
    "  - Re-usable\n",
    "  - Improved readability (factor out complexity)\n",
    "  - Improved testability (test **only** this abstraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple example**\n",
    "\n",
    "`torch.no_grad` disables expensive gradient computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()  # decorator wraps function to disable gradient computation\n",
    "def predict(model, data):  # noqa: F811\n",
    "    # No gradient calculations happen anywhere in this function.\n",
    "    return model(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(model, data):  # noqa: F811\n",
    "    # Gradient computation is active\n",
    "    with torch.no_grad():\n",
    "        # Code in this block runs without gradient tracking.\n",
    "        model(data)\n",
    "    # Gradient computation is active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How can we implement decorators & context managers ourself?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorator function (most common, see a previous lecture):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(\"Before function call\")\n",
    "        result = func(*args, **kwargs)\n",
    "        print(\"After function call\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@function_decorator\n",
    "def my_function(x, y):\n",
    "    print(f\"Inside the function with arguments: x={x}, y={y}\")\n",
    "    return x / y\n",
    "\n",
    "# Syntactic sugar for `my_function = function_decorator(my_function)`\n",
    "my_function(5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorator class (useful for complex state):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassDecorator:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        print(\"Before function call\")\n",
    "        result = self.func(*args, **kwargs)\n",
    "        print(\"After function call\")\n",
    "        return result\n",
    "\n",
    "\n",
    "@ClassDecorator\n",
    "def my_function(x, y):\n",
    "    print(f\"Inside the function with arguments: x={x}, y={y}\")\n",
    "    return x / y\n",
    "\n",
    "\n",
    "my_function(5, 10)  # This calls `MyDecorator.__call__`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@contextmanager` implements a (limited) decorator **and** a context manager:\n",
    "- can run code before/after a function & react to exceptions\n",
    "- **cannot** change arguments, see/modify the return value, skip/delay the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def contextlib_decorator():\n",
    "    print(\"Before function call\")\n",
    "    try:\n",
    "        # this is a generator function since it uses `yield`\n",
    "        yield  # body or decorated functions runs here\n",
    "    except Exception as e:\n",
    "        print(f\"Caught error: {e}\")\n",
    "        # optionally: raise\n",
    "    finally:\n",
    "        print(\"After function call\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use as a decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib_decorator()  # `()` are necessary, even if the decorator has no arguments\n",
    "def my_function(x, y):\n",
    "    print(f\"Inside the function with arguments: x={x}, y={y}\")\n",
    "    return x / y\n",
    "\n",
    "\n",
    "my_function(5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use as a context manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(x, y):  # define without decorator\n",
    "    print(f\"Inside the function with arguments: x={x}, y={y}\")\n",
    "    return x + y\n",
    "\n",
    "\n",
    "with contextlib_decorator():\n",
    "    result = my_function(5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not covered (in **this** lecture): decorators with function args (e.g., `@function_decorator(arg1, arg2)`) and context manager classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "- Many tools for the job (e.g., not using a decorator/CM at all, different kinds of decorators/CMs)\n",
    "- Similar to iterables/iterators:\n",
    "  - which abstraction is suitable depends on the context\n",
    "  - with experience/expertise, you will develop \"taste\" when to use which abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining operator overloading/overwriting & decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ [google-deepmind/alphafold](https://github.com/google-deepmind/alphafold)\n",
    "**Repo purpose:**\n",
    "- Goal: amino acid sequences $\\rightarrow$ 3D protein structures ([website](https://alphafold.ebi.ac.uk/))\n",
    "- Hassabis, Jumper & Baker received the 2024 Chemistry Nobel for work that includes AlphaFold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application example: implementing geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Domain-specific details (e.g., biology) & JAX details are **not** relevant for the exam (unless covered elsewhere).\n",
    "- Python details are relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decorator that creates a custom dataclass**\n",
    "\n",
    "Source: `alphafold/model/geometry/struct_of_array.py`\n",
    "\n",
    "Note: [dataclasses](https://www.youtube.com/watch?v=vBH6GRJ1REM) were introduced in a previous lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "class StructOfArray:\n",
    "\n",
    "  def __init__(self, same_dtype=True):\n",
    "    self.same_dtype = same_dtype\n",
    "\n",
    "  #Â cls is the decorated class\n",
    "  def __call__(self, cls):\n",
    "    # [...]\n",
    "    # monkey patching: changing object at runtime\n",
    "    cls.__len__ = get_len\n",
    "    cls.__getitem__ = get_item\n",
    "    cls.__post_init__ = post_init\n",
    "\n",
    "    # Classes decorated with `StructofArray` becomes a dataclass\n",
    "    # `frozen=True`: dataclass is immutable â†’ hashable â†’ can be used as dict key\n",
    "    new_cls = dataclasses.dataclass(cls, frozen=True, [...])\n",
    "\n",
    "    # [...] JAX optimizations\n",
    "\n",
    "    # decorator returns a new class that wraps the original class\n",
    "    # this new class is initialized via `__init__`\n",
    "    return new_cls\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create optimized datastructure for 3D tensors & overload custom operators for specific geometries**\n",
    "\n",
    "Source: `alphafold/model/geometry/vector.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Float = float | jnp.ndarray  #Â type alias\n",
    "\n",
    "@struct_of_array.StructOfArray(same_dtype=True)\n",
    "class Vec3Array:\n",
    "  \"\"\"Vec3Array in 3 dimensional Space implemented as struct of arrays.\n",
    "\n",
    "  This is done in order to improve performance and precision.\n",
    "  [...]\n",
    "  \"\"\"\n",
    "\n",
    "  # `jnp` is jax.numpy (not covered in this lecture)\n",
    "  # \"struct of arrays\" â€“> separate variables for separate dimension\n",
    "  # more efficient, b/c vector math is component-wise and components (e.g., x) are contiguous in mem (& JAX supports JIT-compilation to exploit this)\n",
    "  x: jnp.ndarray = [...]\n",
    "  y: jnp.ndarray\n",
    "  z: jnp.ndarray\n",
    "\n",
    "  [...]\n",
    "\n",
    "  # Dunder methods below overload operators like `+` (= they define how these operators behave with `Vec3Array` types)\n",
    "\n",
    "  def __add__(self, other: Vec3Array) -> Vec3Array:  # v1 + v2\n",
    "    # `Vec3Array` is a PyTree (a JAX datastructure) with leaves (e.g., JAX arrays)\n",
    "    # `tree_map` applies callable elementwise on leaves (x, y, z) of PyTrees `self` and `other`\n",
    "    return jax.tree_map(\n",
    "      lambda x, y: x + y,  # callable (function), `x + y` calls `__add__` of JAX arrays\n",
    "      self,  # PyTree (this instance)\n",
    "      other  # PyTree (`other`)\n",
    "      )\n",
    "\n",
    "  def __sub__(self, other: Vec3Array) -> Vec3Array:  # v1 - v2\n",
    "    return jax.tree_map(lambda x, y: x - y, self, other)\n",
    "\n",
    "  def __mul__(self, other: Float) -> Vec3Array:  # v1 * 3\n",
    "    return jax.tree_map(lambda x: x * other, self)\n",
    "\n",
    "  def __rmul__(self, other: Float) -> Vec3Array:  # 3 * v1\n",
    "    return self * other\n",
    "\n",
    "  def __truediv__(self, other: Float) -> Vec3Array:  # v1 / 2 (float division)\n",
    "    return jax.tree_map(lambda x: x / other, self)\n",
    "\n",
    "  def __neg__(self) -> Vec3Array:  # -v1\n",
    "    return jax.tree_map(lambda x: -x, self)\n",
    "\n",
    "  def __pos__(self) -> Vec3Array:  # +v1\n",
    "    return jax.tree_map(lambda x: x, self)\n",
    "\n",
    "  [...]\n",
    "\n",
    "  # Similar to `torch.Tensor`, this class implements further non-dunder methods\n",
    "\n",
    "  def dot(self, other: Vec3Array) -> Float:\n",
    "    \"\"\"Compute dot product between 'self' and 'other'.\"\"\"\n",
    "    return self.x * other.x + self.y * other.y + self.z * other.z\n",
    "\n",
    "  def norm(self, epsilon: float = 1e-6) -> Float:\n",
    "    [...]\n",
    "\n",
    "  def norm2(self):\n",
    "    [...]\n",
    "\n",
    "  def normalized(self, epsilon: float = 1e-6) -> Vec3Array:\n",
    "    [...]\n",
    "\n",
    "  [...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application example: decorator\n",
    "Source: `alphafold/data/tools/utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import contextlib\n",
    "import time\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, force=True)  # Ensure Jupyter outputs logs\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def timer(msg: str):\n",
    "  # More performant: This style defers string formatting until after the\n",
    "  # log level is checked. An f-string is always evaluated, wasting\n",
    "  # resources if the message is discarded.\n",
    "  logging.info('Started %s', msg)\n",
    "\n",
    "  tic = time.time()\n",
    "  yield\n",
    "  toc = time.time()\n",
    "  logging.info('Finished %s in %.3f seconds', msg, toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer(\"Example Task\")\n",
    "def example_task():\n",
    "    time.sleep(1.5)\n",
    "\n",
    "\n",
    "example_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_task():\n",
    "    time.sleep(1.5)\n",
    "\n",
    "\n",
    "with timer(\"Example Task\"):\n",
    "    example_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class vs. instance attributes/methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n",
    "- Share one attribute (**one** memory address) with many instances\n",
    "  - This lecture: use a static class attribute (less code, but more \"global\" & less flexible)\n",
    "  - Alternative: pass the **same** object into each instance\n",
    "- Build a \"factory\" (creates new instances)\n",
    "  - This lecture: use `@classmethod` decorator (â†’ simpler API; easier subclassing)\n",
    "  - Alternative: write a separate function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above: which tool to use depends on the context!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ General example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer(model_name: str):\n",
    "    print(f\"--- SLOW OPERATION: Loading '{model_name}' tokenizer from disk... ---\")\n",
    "    time.sleep(1)  # Simulate I/O delay\n",
    "    return lambda text, max_len: f\"Tokenized and truncated to {max_len}: '{text[:max_len]}...'\"\n",
    "\n",
    "\n",
    "class Processor:\n",
    "    _tokenizer = None  # shared cache across multiple instances (*one* memory address used by *all* instances)\n",
    "\n",
    "    @timer(\"init\")\n",
    "    def __init__(self, max_length: int):\n",
    "        self.max_length = max_length\n",
    "        self._ensure_tokenizer_loaded()\n",
    "        # Replace the above line by the below line would reload the tokenizer once for every instance (*one* memory address for *each* instance)\n",
    "        # self._tokenizer = load_tokenizer(\"4o-tokenizer\")\n",
    "\n",
    "    @classmethod\n",
    "    # `cls` points to class (name by convention: the first arg points to class irrespective of how it's named)\n",
    "    # type hint: Python resolves type later, `Processor` does not exist yet\n",
    "    def _ensure_tokenizer_loaded(cls: \"Processor\"):\n",
    "        if cls._tokenizer is None:\n",
    "            # this happens (ideally) only once\n",
    "            cls._tokenizer = load_tokenizer(\"4o-tokenizer\")\n",
    "\n",
    "    @timer(\"process\")\n",
    "    def process(self, text):\n",
    "        # `type(self)` is `Processor` (flexible for subclassing).\n",
    "\n",
    "        # `self._tokenizer` looks for instance attr (does not exist) & falls back to class attr\n",
    "        # However: `_tokenizer`'s value is a function â€“> for `self.<function>`, Python passes `self` as first arg â€“> error\n",
    "        # â€“> we use `<class>._tokenizer` instead\n",
    "\n",
    "        return type(self)._tokenizer(text, self.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor1 = Processor(20)  # slow\n",
    "processor1.process(\"Language modelling via autoregr. or diffusion models?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor2 = Processor(25)  # fast\n",
    "processor2.process(\"Student: \\\"Should I consider a PhD\\\"?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can swap out the class attr later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Processor._tokenizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor2 = Processor(25)  # fast\n",
    "processor2.process(\"Student: \\\"Should I consider a PhD\\\"?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation to dataclasses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Student:\n",
    "    name: str\n",
    "    university: str = \"Berlin\"  # classâ€level default; treated as a field blueprint\n",
    "\n",
    "# Decorator reads class vars (type + default) and implicitly generates:\n",
    "#   def __init__(self, name, university=\"Berlin\"):\n",
    "#       self.name = name\n",
    "#       self.university = university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Student(\"Alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Student(\"Bob\", university=\"Munich\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ [openai/improved-diffusion](https://github.com/openai/improved-diffusion): `improved_diffusion/logger.py`\n",
    "\n",
    "All logger instances have global config:\n",
    "```python\n",
    "class Logger:\n",
    "    DEFAULT = None  # allows swapping default logger globally\n",
    "    CURRENT = None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ [karpathy/nanochat](https://github.com/karpathy/nanochat): `scripts/tok_train.py` & `nanochat/tokenizer.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class RustBPETokenizer:\n",
    "    \"\"\"Light wrapper around tiktoken (for efficient inference) but train with rustbpe\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def train_from_iterator(cls, text_iterator, vocab_size):\n",
    "        # 1) train using rustbpe\n",
    "        tokenizer = rustbpe.Tokenizer()\n",
    "        # the special tokens are inserted later in __init__, we don't train them here\n",
    "        vocab_size_no_special = vocab_size - len(SPECIAL_TOKENS)\n",
    "        assert vocab_size_no_special >= 256, f\"vocab_size_no_special must be at least 256, got {vocab_size_no_special}\"\n",
    "        tokenizer.train_from_iterator(text_iterator, vocab_size_no_special, pattern=SPLIT_PATTERN)\n",
    "        # 2) construct the associated tiktoken encoding for inference\n",
    "        pattern = tokenizer.get_pattern()\n",
    "        mergeable_ranks_list = tokenizer.get_mergeable_ranks()\n",
    "        mergeable_ranks = {bytes(k): v for k, v in mergeable_ranks_list}\n",
    "        tokens_offset = len(mergeable_ranks)\n",
    "        special_tokens = {name: tokens_offset + i for i, name in enumerate(SPECIAL_TOKENS)}\n",
    "        enc = tiktoken.Encoding(\n",
    "            name=\"rustbpe\",\n",
    "            pat_str=pattern,\n",
    "            mergeable_ranks=mergeable_ranks, # dict[bytes, int] (token bytes -> merge priority rank)\n",
    "            special_tokens=special_tokens, # dict[str, int] (special token name -> token id)\n",
    "        )\n",
    "        return cls(enc, \"<|bos|>\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Resolution Order\n",
    "### ðŸŸ¦ General example\n",
    "\n",
    "How to deal with multiple parent classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def greet(self):\n",
    "        return \"Hello from A\"\n",
    "\n",
    "\n",
    "class B:\n",
    "    def greet(self):\n",
    "        return \"Hello from B\"\n",
    "\n",
    "\n",
    "class C(A, B):\n",
    "    pass\n",
    "\n",
    "\n",
    "c = C()\n",
    "print(c.greet())\n",
    "print([cls.__name__ for cls in C.mro()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> âš ï¸ **Avoid deep inheritance trees**\n",
    "> Code tightly coupled â†’ difficult to debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative: \"has-a\" instead of \"is-a\" relationships:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"has-a\" logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine:\n",
    "    def start(self): ...\n",
    "\n",
    "\n",
    "class Car:\n",
    "    def __init__(self, engine: Engine):\n",
    "        self.engine = engine   # has-a\n",
    "\n",
    "    def drive(self):\n",
    "        self.engine.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"is-a\" logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine:\n",
    "    def start(self): ...\n",
    "\n",
    "\n",
    "class CarWithElectricEngine(Engine):\n",
    "    def drive(self): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixins\n",
    "### ðŸŸ¦ General example\n",
    "Avoid complexity (overwriting) by using Mixins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlyMixin:\n",
    "    def fly(self):\n",
    "        print(\"Flying\")\n",
    "\n",
    "\n",
    "class SwimMixin:\n",
    "    def swim(self):\n",
    "        print(\"Swimming\")\n",
    "\n",
    "\n",
    "class Animal:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "\n",
    "class Duck(Animal, FlyMixin, SwimMixin):\n",
    "    pass\n",
    "\n",
    "\n",
    "duck = Duck(\"Daffy\")\n",
    "duck.fly()\n",
    "duck.swim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ [adapter-hub/adapters](https://github.com/adapter-hub/adapters)\n",
    "\n",
    "**Repo purpose:** add-on library to HuggingFace's Transformers, e.g., for quantized training"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
